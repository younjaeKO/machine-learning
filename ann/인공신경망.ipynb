{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba29b428",
   "metadata": {},
   "source": [
    "# diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8738278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65477dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234361ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57e550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c92d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 20:28:46.558260: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(12, input_dim=8, activation='relu'),\n",
    "  tf.keras.layers.Dense(8, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68f2c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 20:34:18.473408: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 10.5945 - accuracy: 0.6562\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4772 - accuracy: 0.6302\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.1683 - accuracy: 0.6510\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0672 - accuracy: 0.6471\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9837 - accuracy: 0.6510\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9103 - accuracy: 0.6706\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8292 - accuracy: 0.6654\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7764 - accuracy: 0.6810\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7566 - accuracy: 0.6771\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.7148\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7392 - accuracy: 0.7057\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6836\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.6992\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.7083\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.7057\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6966\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.7135\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.7135\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.7214\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.7201\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6210 - accuracy: 0.7122\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.7227\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.7161\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6953\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.7266\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6966\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6196 - accuracy: 0.7214\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.7188\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.7057\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.7240\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.7201\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.7109\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.7331\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7122\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.7174\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.7174\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7201\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7279\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7188\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7305\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7109\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7174\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.7174\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7305\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7122\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7292\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7227\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7161\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7083\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7201\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7344\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7188\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7227\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7305\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7409\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7227\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7109\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7305\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7122\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7148\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7305\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7305\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7370\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7266\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.7240\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7070\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.7266\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7227\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7148\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7292\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7331\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7383\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7474\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7344\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7305\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7344\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7396\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7422\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7240\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7227\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.7292\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7292\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7422\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7500\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7422\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7448\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7305\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7448\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7396\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7526\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7435\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7383\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7396\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7448\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7526\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7500\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7357\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7539\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5450 - accuracy: 0.7279\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.7448\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7409\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7487\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7422\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7396\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7474\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7591\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7279\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7487\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7435\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7474\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7474\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7435\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.7305\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7630\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7604\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7161\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7461\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7474\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7565\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7539\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7526\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.7292\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7448\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7487\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7656\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7461\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7344\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7331\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7513\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7448\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7396\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7461\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7487\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7578\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7617\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7448\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7526\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7526\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7396\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7578\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7578\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7461\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7383\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7552\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7474\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7487\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.7474\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.4983 - accuracy: 0.7643\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 938us/step - loss: 0.5012 - accuracy: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff24aa57910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d223aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 712us/step - loss: 0.4979 - accuracy: 0.7656\n",
      "Accuracy: 76.56\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2074a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "\n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00b1739",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/yn3wwcpd281f44kybjy23xlr0000gn/T/ipykernel_41576/3045056302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s => %d (expected %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X)\n",
    "\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8337078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec889c",
   "metadata": {},
   "source": [
    "# fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf3fea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c501873",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b1e7cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8ca2c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPG             0\n",
       "Cylinders       0\n",
       "Displacement    0\n",
       "Horsepower      6\n",
       "Weight          0\n",
       "Acceleration    0\n",
       "Model Year      0\n",
       "Origin          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cf6ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Europe  Japan  USA  \n",
       "393          82       0      0    1  \n",
       "394          82       1      0    0  \n",
       "395          82       0      0    1  \n",
       "396          82       0      0    1  \n",
       "397          82       0      0    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f2d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aa9f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37c5fded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5.478  195.318  104.869 2990.252   15.559   75.898    0.178    0.197\n",
      "     0.624]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "266f8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 9)                 19        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,884\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 19\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "      normalizer,\n",
    "      layers.Dense(64,  activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c663ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29c896a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 23.0390\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 22.2189\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.2724\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 20.0089\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18.2789\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.9585\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.3817\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 10.6904\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.4349\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1960\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4201\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6835\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3744\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.1214\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.9338\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.7768\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6420\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4868\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.3644\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2764\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2034\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1655\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1185\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0923\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0667\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0499\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0364\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0012\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0022\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9986\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9752\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9648\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9595\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9499\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9468\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9297\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9480\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9257\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9231\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9004\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9104\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9308\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8886\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8714\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8555\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8562\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8571\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8493\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8482\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8442\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8212\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8279\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8359\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8459\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7878\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7967\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8053\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8014\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7766\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7919\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7816\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7922\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8014\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7614\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7658\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7633\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7728\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 1.7579\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7549\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7515\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7483\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7720\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7295\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 956us/step - loss: 1.7603\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7370\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7480\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7471\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7454\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7262\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7257\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 1.7160\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7125\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7147\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7165\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7380\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7033\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 1.7195\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7116\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6795\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 998us/step - loss: 1.6917\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6897\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6972\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 981us/step - loss: 1.6836\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6986\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6984\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6945\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7176\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7048\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6841\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff22d4f7350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d7cc266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7271851301193237"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = model.evaluate(test_features, test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26373a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhXElEQVR4nO3de5hcdZ3n8feni+5JBzCdCMTYgmEQwcglNwc0o8sdRgSai0JcZmAeRmZnHR/HZZgNDkbdR5cojrKy7DNGZciIBpCQEGGUzYaLdyAhgRABGbkk6WRIgDQQ0iTd1d/945zqVFefqjpV3afqVNX39Tz9VJ/Tdfk1pj/+7j+ZGc45V6m2ehfAOdeYPDycc1Xx8HDOVcXDwzlXFQ8P51xVPDycc1XZL8k3l/QC8AaQBQbNbK6kKcDtwHTgBeATZrYzyXI458ZfLWoeJ5vZTDObG14vAFab2ZHA6vDaOddg6tFsOQ9YEn6/BOipQxmcc2OkJGeYSnoe2AkY8B0zWyypz8y68p6z08wmR7z2SuBKgP3333/O0UcfnVg5nWtVQ2Y8//Kb9G165mUzO7iS1yba5wHMM7Otkg4BVkl6Ou4LzWwxsBhg7ty5tmbNmqTK6FxL2rVnkMtvfoTXNvfRd93ZL1b6+kSbLWa2NXzcDiwH/gR4SdI0gPBxe5JlcM6NlguOdZv7+PYls6p6j8TCQ9L+kg7MfQ+cATwJrAQuC592GXB3UmVwzo1WGBxnHzetqvdJstkyFVguKfc5PzKzn0l6FLhD0hXAJuDjCZbBOZdnvIIDEgwPM3sOOD7i/ivAqUl9rnMu2ngGB/gMU+dawngHB3h4ONf0kggO8PBwrqklFRzg4eFc00oyOMDDw7mmlHRwgIeHc02nFsEBHh7ONZVaBQd4eDjXNGoZHODh4VxTqHVwgIeHcw2vHsEBHh7ONbR6BQd4eDjXsOoZHODh4VxDqndwgIeHcw0nDcEBHh7ONZS0BAd4eDjXMNIUHODh4VxDSFtwgIeHc6mXxuAADw/nUi2twQEeHs6lVpqDAzw8nEultAcHeHg4lzqNEBzg4eFcqjRKcICHh3Op0UjBAR4ezqVCowUHeHg4V3eNGBzg4eFcXTVqcICHh3N108jBAR4eztVFowcHeHg4V3PNEBzg4eFcTTVLcICHh3M100zBAR4eztVEswUHeHg4l7hmDA7w8HAuUc0aHFCD8JCUkbRO0j3h9RRJqyQ9Gz5OTroMztVDMwcH1Kbm8VngqbzrBcBqMzsSWB1eO9dUmj04IOHwkPQu4Gzge3m3zwOWhN8vAXqSLINztdYKwQHJ1zxuAP4BGMq7N9XMtgGEj4dEvVDSlZLWSFqzY8eOhIvp3PholeAA2C+pN5b0MWC7ma2VdFKlrzezxcBigLlz59r4ls658bNiXS/X3/cMvX39dGTaGBwa4sb5s5s6OCDB8ADmAedK+igwAXibpFuBlyRNM7NtkqYB2xMsg3OJWrGul2vu2kD/QBaAvdkhOjJtDGSHyryy8SXWbDGza8zsXWY2HbgEuN/MLgVWApeFT7sMuDupMjiXtOvve2Y4OHL2Zoe4/r5n6lSi2qnHPI9FwOmSngVOD6+da0i9ff2R97cWud9Mkmy2DDOzB4EHw+9fAU6txee61pHrd9ja1887uzq5+syj6JnVnehn7tozSEemjb0RTZR3dnUm+tlpUJPwcC5Jhf0OvX39XHPXBoDEAiQ3qjI4NDQqQDrbM1x95lGJfG6a+PR01/Ci+h36B7KJ9TvkD8feOH82X7/oOLq7OhHQ3dXJdRccm3itJw285uEaXrH+hST6HYrN40gqLOrRHIvLax6u4RXrXxjvfodaTwDLNcd6+/ox9jXHVqzrTfRz4/LwcA3v6jOPorM9M+LeePc71GPmaK2bY5XyZotreLlqfLnqfbVNgHpNOa9lc6waHh6uKfTM6i4ZBNWOyNRzrco7uzoj55GkZRjYmy2uJVTTBKj3IrdaNMfGwmseriXEbQKkaZFb3OZYvXh4uJZQrAnQJrFiXS89s7pTucitXHOsnrzZ4lrC1WceRXubRt3Pmg0Pf7byIrdqeHi41jE6O4B9fR+tvMitGh4eriVcf98zDGSL7ymV6+OIkpbRjbTxPg/XlArndBSrVeTkOkdbdZFbNTw8XNOJmtNRSpsYHlX5zXMvs/ThzWTNyEhcOKc2HZZpXsNSjDdbXNOJ6vgs58b5sxnIDrFsbS9ZC5o3WTOWre1NfC1J2tewFOPh4ZpOpR2cuXkc9VpLkvY1LMWUbLZI+naM93jdzK4dp/I4N2Zx+jhypkzsGJ4AVq+1JGlfw1JMuZrHecDaMl8XJllA5yoVNaejDWjPjLzXkWlj4Tkzhq9rtbQ/7vunfZSnXIfpt8xsSakn+FmzLpUK5nRkMuKC2d0sf2wre7NDTJnYwcJzZozolLz6zKNGdLRCbUZb6vW5Y1UyPMzshnJvEOc5ziUtf7SiTRru9MwZyBrLH9tK1oybPhm9VqVea0nSvoalGJkVnzgj6f3AEWa2Mrz+FjAp/PH/NrPHki9icGLcmjVravFRLoXKDWMWDs2WUiw4Wp2ktWY2t5LXlOvzWAS8nHd9JnAv8ACwsLLiOVe5OMOYcYdm8ztH3diVC49pZvbrvOvXzWyZmf0AOCjBcjkHxBvGjDMqUdg56sauXHgcmH9hZifmXUaebu/ceIozjFluVKIN+PpFx6W+D6HRlAuPrZJOKLwp6URgazJFcm6fOMOYUTtu5TOSOxqhlZUbqv3vwO2SbgFynaNzCA6ovjjBcjnHinW9vLlncNT9wmHMXDBcdcfjo0ZZIP3zJRpVyZqHmT0CnABkgMvDrzbgxPBnziUi11Ha1z8w4v7kie2RJ7L1zOrmq+cfQ+F+P40wX6JRxVlV2w08ASw1s6cSLo9zQPERlIkd+0U2QXbtGeTOtVuAYFRl5+69DTNfolGVW9uyELiUYBr61yVdZ2bfrUnJXEurZL1H4dmxcYdjG3EZfJqUq3lcDMw0s92S3g78DPDwcIkrdWZJ/h/9OyZNYEJ7hk2v7q7oeIRqz3Fx+5SbYbrWzOYUu64Vn2HaeqJmjXa2Z7hwTjfL1vaOatJ8+MiDeG7Hm7FPjIuawg7BKfe/WnBKMr9UilUzw7RczeMISStz719wjZmdW2EZnYul2HqPYn0hv3h230ToqFpEYRhFBQekfxl8mpQLj/MKrr+RVEFc67p2xYYRW//NP+FQvtJzbOSZJZ+7fX2s98zNQs0PoThT2H1YN75yq2ofqvaNJU0Afg78Ufg5d5rZFyVNAW4HpgMvAJ8ws53Vfo5rbNeu2MCtv900fJ0149bfbmLZ2i28NTA0qgnyjkkT2PbaW7HeO78WEadG4cO6lSk32vJEqZ+b2XElfrwHOMXMdklqB34p6afABcBqM1skaQGwgGAymmtBSx/eHHm/fyDYwTy/CXLajKlMKDGTtFB+LaJYB2xGYsjMR1uqUK7ZMkQwu/dHwE+A2A1CC3pid4WX7eGXETSFTgrvLwEexMOjZRXre8jXP5Dlaz97mlt/+yKbXt3NxI4Mu/eWboIU1iKKbbgTNeHMxVNuhulMYD5wAEGAfBV4P9BrZi+We3NJGUnrge3AKjN7GJhqZtvC999GkQV2kq6UtEbSmh07dsT/jVxDUZFT3Apte+2t4dPq/+f5x45ay9LeJiZPbEcEIyaFodAzq5vrLjiW7q7Oos9xlSk5VDvqydLFwE3A18zs+gpe1wUsBz4D/NLMuvJ+ttPMSm5l6EO1zWvGF37K7oF4B0nnb+TjE7zGVxJDtUjqBi4Bzgd2Ap8jCILYzKxP0oPAWcBLkqaZ2TZJ0whqJa5F9ccMjss/NH3EBLA0nx7fKko2WyQ9RNDX0U6wKO4ygp3EOsJRk1KvPTiscSCpEzgNeBpYGb4P4ePd1RffNbquie1ln5MRzDy0K/nCuIqUq3m8m6CT86+BK/PuK7z/xyVeOw1YIilDEFJ3mNk9kn4D3CHpCmAT8PFqC+8aX5xWc9YYMWfDpUO5eR7Tq31jM3sCmBVx/xXg1Grf1zWX1wqW3BfjMz/Tp9w8j3eY2X+M9TmuuVTbWRn1urinu8Vp3rjaKrcN4b/FeI84z3FNotpDmYu97uSjDy65hWBOBYOCrkbKhcfxkl4v8fUGMLUWBXXpUO2hzMVe98DTO/jiOTPoyJT+pxi3eeNqp9wksYyZva3E14Fm5r1YLaTaQ5mL/by3r587124ZPsmtu0HPbW1F5Woezo1Q7aHMxX7ekWkbnjl69nHTIndC9wVr6eTh0SJWrOtl3qL7OXzBvcxbdH/ZPopiqv3jjnpdm2BwaGjEDmA+jbxxxNkA2TW48dxyr9pDmfNf19vXT0emjcGhocg9R332aGOIFR6SjgC2mNkeSScBxwH/amZ9yRXNjZdSnZzV/JFW8sddODz7mVPew51rt1S8WbFLn7g1j2XAXEnvAb5PMMX8R8BHkyqYGz/VdnKOVVSN5/PLgxrPjfNnM5AdYt6i+31xW4OK2+cxZGaDBIvjbjCzzxFMP3cNoNpOzrGKqvEMGXR1djCQHRo17+Pvbl/P+77w06r7Y1xtxQ2PAUnzCRay3RPe8yl/DSKpEYxynbDFajY7d+8tuqdo/8AQV//4cQ+QBhA3PP4S+CDwVTN7XtLhwK3JFcuNpyRGMOLMNC1V4ynVZBoYsrKTzlz9VbQZUL34ZkDpM2/R/ZFrUvLPPbntkU18fvkGhvL+ieW2/suNuhQj4PlFZ493sV0R1WwGFKvmIWmepFWSfi/pOUnPS3quumK6ZlCuE7bw7NjCGs/VZx5FqR0IfUZp+sUdbfk+wQ5ia4Hyh1+4pldsNWzXxHY+eN3q4eMRLv/QdL507vtHPa9nVjdrXnx1xLELOe1t8hmlDSBun8drZvZTM9tuZq/kvhItmUu1qE7Y9ox4o39gxLkqtz+6uWjn51d6juWGi2cyOW+5fVdnO9d//Hgfsm0Asfo8JC0CMsBdBOexAGBmjyVXtH28zyOdCieA7XprgNfeGhz1vFY9/7WRJLIBcuiE8DH/zQ3wfxEtLH+m6a49gxzzxfsinxdnsx/XeGKFh5mdnHRBXOPatWeQy29+pORzDl9wr88ibTJxR1smSfpm7hAmSf8kaVLShXPplwuOdZv7Sj6vkl3HXGOI22F6M/AG8Inw63XgX5IqlGsMtz2yidn/YxVrXtzJpAntdHWWn3QcZ9cx1xjihscRZvZFM3su/PoypY9dcE0uNwFsbzY4tOnV3Xt5c+8g7W3lz4/s7esf054iLh3ihke/pD/NXUiaRwWHXrvmsmvPIAvv3jhi5ijAQNY4YMJ+w9PgMyUOovUmTOOLO9ryNwQHOE0imDn8KsEJcq7F5Po4cjWOQn27B1i38Axg9JL8QmPZU8TVX9zRlvUEO6m/Lbx+PclCufTIn8vxjkkTmNCeYdOru5kysYNXd+8d9fz8aeWFu4dF8cOcGle5Q58uNbNbJf23gvsAmNk3EyybG0fVHNRUWHPIn3I+89CuUbWKqGX+ubkgxRbS+RqWxlWuz2P/8PHAiK8DEiyXG0flls8X25ej2J4bq373Ej2zurlwTvdwv0ZG4sI5xbcn9F3Rm0+5s2q/E377/8zsV/k/CztNXQMod1BTsc2RSzU1VqzrZdnaXrLh8oasGcvW9jL33VMiA6TajZNdesVd2/KYmc0udy8pvrZlbA5fcC9R/yuL4qtjJ09sZ+fu6FPacgczldvPwzWOcV/bIumDwIeAgwv6Pd5GsFDONYBiAVFqR69iwSGCJsjnbl8f+XPvAG0d5fo8Ogj6NvZjZH/H68BFyRbNVauwDyPqMOlcf0OlHZZG0ASp16bKLj3K9Xk8BDwk6RYze7FGZXJjEHXcwbK1vVw4p5sHnt4R2d9QOGrSJkZNAMvJNVmuPvOoWKMtrnnFnWH6PUlduQtJkyVFr792dVWsc/TeJ7ZFPj9/c2Rg+LT6yz80veToiB8L6eLOMD0o/3Q4M9sp6ZBkiuTGolQfRq4fI39EBYofATnz0K6SoyN+LGRrixseQ5IOM7NNAJLeDZEd+K7OinWOFuofyPKllRvZMzg0XFPZmx2iI9PGQDj13MPBlRK32fKPwC8l/UDSD4CfA9eUeoGkQyU9IOkpSRslfTa8PyXcif3Z8HHy2H4Fl6/cruT5+voHRjVx9maHfMm8iyVWeJjZz4DZwO3AHcAcMyvX5zEIXGVm7wNOBD4taQawAFhtZkcCq8NrN056ZnWPuUrow60ujpLhIeno8HE2cBiwFegFDgvvFWVm23IbJJvZG8BTQDdwHrAkfNoSoGcM5XcRusc4XOrDrS6Ocn0eVwGfAv4p4mexN0CWNB2YBTwMTDWzbRAETLGOV0lXAlcCHHbYYXE+xoVOPvpgfvjbTbFqIB2ZthHL66OGW6tZVOeaX+LHTUo6AHiI4JzbuyT1mVlX3s93mlnJfg+fnl5a/h9318R2dr01yECxiRp59u/I8ObeLBmJrBndEcEQtSdH7shID5DmkcT09AtK/dzM7irz+nZgGfDDvOe+JGlaWOuYBmyvpMBupMI/7mLTyqO8uTd4TdZsuMZRGAilFtV5eLS2cs2Wc8LHQwjWuNwfXp8MPEhwCFQkBZt+fB94qmDfj5XAZcCi8PHuikvtgCA4rrrj8eGVrWNRLBDKnUnrWle56el/CSDpHmBGrq8irDHcVOa95wF/DmyQtD6893mC0LhD0hXAJuDjVZe+heVqHOMRHDlRgVBqUZ1rbXEniU3PBUfoJeC9pV5gZr+EolMOTo35ua6IYhv1jEVUIPgaFldM3PB4MFzLspRglOUS4IHESuVGKRzxGO8jHIudTO+b+Lhi4m6A/LeSzgc+Et5abGbLkyuWyxe1UlZUvz6gq7OdN/YMks0fkSkxLdWnqbsocaenAzwG3GtmnwPuk3RgQmVyBaKaKMbov/fO9gyXnngY+5UIgu6uTvb/o/1GBgfBmSs+Ld1VIu5ZtZ8C7gRye5p2AysSKpMrUGxkw2DUkvhj3jmJbJEqSa6vwkdQ3HiIW/P4NMHoyesAZvYswfCtq4FyIxvfungmv1pwCqfNmMrCuzdGNmcy0vDELt8FzI2HuOGxx8yGT/iRtB++JL9moo4tyMntzXHbI5tKnuQ2ZDbcb+HHILjxEHe05SFJnwc6JZ0O/FfgJ8kVy+Urd/Ja/0CWhXdvJGtW8UluPoLiqhX36AUBfwWcQdBPdx/wPUt6YUzI17bsU+wYBYCbPjmbgeyQr0VxFRv3tS3hm7YBT5jZMcB3qy2cGx/F5nhMmdjB2cdNG772WoVLWtnwMLMhSY/nb0Po6idqxmdHpo2F58wYvvZ5Ga4W4vZ5TAM2SnoEeDN308zOTaRULeLaFRtY+vBmsmZkJOafcChf6Tm25Gt6ZnXzVtjHsTc7xJSJHSw8ZwY9s7p93w1XU3HD48uJlqIFXbtiA7f+dl9FLms2fF0qQHbtGeTOtVvImnHTJ2cPN1WiZqHmdkj3AHFJKLefxwTgvwDvATYA3zezwVoUrNktfXhz0fv54ZFfm3jHpAlMaM+w6dXdfPuSWaP6OHzfDVdL5WoeS4AB4BfAnwEzgM8mXahWUGwpfdaMeYvuj9wVbNtrbwHBgUz5wQG+74arvXKTxGaY2aVm9h2Cs2k/XIMytYSMii9A6e3rxwh2BYvaTnDV714adc9njbpaKxcew3vaeXNlfM0/4dCqXxs1VOuzRl2tlWu2HC/p9fB7EcwwfT383szsbYmWronl+jXyR1vi7goWVWvxWaOu1hLfPX08tMoM03mL7o+9yc8Li85OuDSulVQzw7SS/TxcwkotgMs31kOdnBsPHh4p0jOrm3NnjhxFybSNbKJ4P4ZLCw+PFLntkU38eM2WEffagMkT20ds+OP9GC4N4s4wdQkonAC2/Y09FI7MDgwZEzv2Y93CMyJf5x2jrl48POpkxbperr7zcQayIyeARcnvRPVp6C4tvNlSJ1/+ycbh4Cgnf2i21DR052rJax41lN/cqGSAPH/+h09Dd2nh4VGlSvsdok6bjyt/aNaPf3Rp4c2WKuSCILcGJdfvsGJdb9HXVHs8ZOHQrE9Dd2nh4VGFavod4jYr9u/IjDqLJb9G0zOrm+suOLbkc5yrBW+2VKGafoc458u2Z8RXzy8fBL7NoEsDr3lUoZrl75855T0UTBalPSO6OvdNALv+ouM9FFzD8JpHFaI2IW7PiDf3DHL4gntHdaDmtg6EYJfznbv3+uQu1/A8PKpQuPw9t+NXX3+w/Un+xK3TZkzl8psfYd3mPm6cP3vUDmDONSpfkj8Oii2lnzZpAt1dnazb3Ddqz1Hn0iSRQ59cecU6Sre99hbb39jjweGaUmIdppJulrRd0pN596ZIWiXp2fBxclKfX0ulOko9OFyzSnK05RbgrIJ7C4DVZnYksDq8bnjFNvGJ2uXcuWaRWHiY2c+BVwtun0dwnAPhY09Sn19LuYlb0yZNGL53+Yem86Vz31/HUjmXrFrP85hqZtsAwsdDij1R0pWS1khas2PHjpoVsFqnzZhKd1cnmTZx0ydne3C4ppfaSWJmttjM5prZ3IMPPrjexSlp157B4eFY7+NwraLW4fGSpGkA4eP2Gn/+uPPgcK2q1uGxErgs/P4y4O4af/648uBwrSzJodqlwG+AoyRtkXQFsAg4XdKzwOnhdUPy4HCtLrFJYmY2v8iPTk3qM2vFg8O5FHeYppUHh3MBD48KeHA4t4+HR0weHM6N5OERgweHc6N5eJThweFcNA+PEjw4nCvOw6MIDw7nSvPwiODB4Vx5Hh4FPDici8fDI48Hh3PxeXiEPDicq4yHBx4czlWj5cPDg8O56rR0eHhwOFe9lg0PDw7nxqYlw8ODw7mxa7nw8OBwbny0VHh4cDg3flomPDw4nBtfLREeHhzOjb+mDw8PDueS0dTh4cHhXHKaNjw8OJxLVlOGhweHc8lruvDw4HCuNpoqPDw4nKudpgkPDw7naqspwsODw7naa/jw8OBwrj4aOjw8OJyrn4YNDw8O5+qrIcPDg8O5+mu48PDgcC4dGio8PDicS4+GCQ8PDufSpS7hIeksSc9I+ndJC8o9f8jMg8O5lNmv1h8oKQPcBJwObAEelbTSzH5X7DXPv/wmr3lwOJcq9ah5/Anw72b2nJntBW4Dziv1gt17sx4czqVMzWseQDewOe96C3BC4ZMkXQlcGV7u+djx73yyBmUbDwcBL9e7EBVopPI2Ulmhscp7VKUvqEd4KOKejbphthhYDCBpjZnNTbpg46GRygqNVd5GKis0Vnklran0NfVotmwBDs27fhewtQ7lcM6NQT3C41HgSEmHS+oALgFW1qEczrkxqHmzxcwGJf0tcB+QAW42s41lXrY4+ZKNm0YqKzRWeRuprNBY5a24rDIb1d3gnHNlNcwMU+dcunh4OOeqkurwqHQae61JulnSdklP5t2bImmVpGfDx8n1LGOOpEMlPSDpKUkbJX02vJ/W8k6Q9Iikx8Pyfjm8n8ryQjB7WtI6SfeE12ku6wuSNkhanxumrbS8qQ2PvGnsfwbMAOZLmlHfUo1yC3BWwb0FwGozOxJYHV6nwSBwlZm9DzgR+HT43zOt5d0DnGJmxwMzgbMknUh6ywvwWeCpvOs0lxXgZDObmTcXpbLymlkqv4APAvflXV8DXFPvckWUczrwZN71M8C08PtpwDP1LmORct9NsL4o9eUFJgKPEcxETmV5CeYrrQZOAe5J+78F4AXgoIJ7FZU3tTUPoqexd9epLJWYambbAMLHQ+pcnlEkTQdmAQ+T4vKGzYD1wHZglZmlubw3AP8ADOXdS2tZIZjV/X8lrQ2XgkCF5a3H9PS4Yk1jd5WRdACwDPg7M3tdivrPnA5mlgVmSuoClks6ps5FiiTpY8B2M1sr6aQ6FyeueWa2VdIhwCpJT1f6BmmueTTqNPaXJE0DCB+317k8wyS1EwTHD83srvB2asubY2Z9wIME/UtpLO884FxJLxCsEj9F0q2ks6wAmNnW8HE7sJxgtXtF5U1zeDTqNPaVwGXh95cR9C3UnYIqxveBp8zsm3k/Smt5Dw5rHEjqBE4DniaF5TWza8zsXWY2neDf6f1mdikpLCuApP0lHZj7HjgDeJJKy1vvjpsynTofBX4P/AH4x3qXJ6J8S4FtwABBTekK4O0EHWfPho9T6l3OsKx/StDsewJYH359NMXlPQ5YF5b3SWBheD+V5c0r90ns6zBNZVmBPwYeD7825v62Ki2vT093zlUlzc0W51yKeXg456ri4eGcq4qHh3OuKh4ezrmqeHg456ri4ZFykt4eLpteL+k/JPXmXXeMw/t/SdJ1BfdmSnqqzGv+fqyfXeL9c8vF54bXD0rapLy59JJWSNoVfj9dUn/43+R3kv5ZUlv4syMl3SPpD+E6jgckfST82cXhdg/3JPW7NDMPj5Qzs1csWDY9E/hn4Fu5azPbK2ms65OWAhcX3LsE+NEY33esTjaz/OMA+gimgRPOPC08AewP4X+j4wi2cOiRNAG4F1hsZkeY2RzgMwSTpDCz24G/SvB3aGoeHg1I0i2SvinpAeBrhTUBSU+GK2eRdGm4qc56Sd8J90kZZmbPAH2S8g/e+gRwm6RPSXo03JBnmaSJEWV5MK+GcFC4viO3Ivb68PVPSPrr8P40ST8Py/OkpA/H/LVvIwg1gAuAu6KeZGaDwK+B9wD/GfiNma3M+/mTZnZLzM90JXh4NK73AqeZ2VXFniDpfQS1innh/ytnCf6gCi0l/MMMN9x5xcyeBe4ysw9YsCHPUwTT7+O6AnjNzD4AfAD4lKTDgU8S7NMyEzieYJp8HKuBj4Thdwlwe9STwoA7FdgAvJ9gHxCXgDQvyXel/diCJeulnArMIThMHKCT6JWStwG/lnQVwR/m0vD+MZK+AnQBBxAclxHXGcBxki4KrycBRxIseLw5XOG7wszWx3y/LPBLgjDsNLMXCrYTOCLc+8OAu83sp5JOz3+CpOVhGX5vZhdU8Lu4CB4ejevNvO8HGVmLnBA+ClhiZteUeiMz2xw2N/4TcCHBLm4QbLPYY2aPS7qcYNFXofzPnpB3X8BnzGxU4IQdlmcDP5B0vZn9a6ny5bmNYPn4lyJ+luvzyLcR+EjuwszOD5tY34j5ea4Eb7Y0hxeA2QCSZgOHh/dXAxeFG77kNrh9d5H3WAp8i+CPcEt470BgW1hLiGru5D57Tvj9RXn37wP+Jnwtkt4bLgV/N8HGOd8l2CJgdgW/5y+A69hXMyrnR8A8Sefm3RvVb+Oq4zWP5rAM+Iuw2v4owTYGmNnvJF1LsN1cG8HWAZ8GXox4jx8D/4tgNCLnCwRbFb5I0IdwYMTrvgHcIenPgfvz7n+PYH/Xx8Ih1h1AD0Ht5WpJA8Au4C/i/pIWLAGPXWsws34Fu3x9U9INwEvAG8BX4r6HK86X5LvUCZtQc83s5Rp81knA35vZx5L+rGbjzRaXRjuA1bkh4KRIuhj4P8DOJD+nWXnNwzlXFa95OOeq4uHhnKuKh4dzrioeHs65qvx/9aC/K/JiUtUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effb16e",
   "metadata": {},
   "source": [
    "# Bankrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d5d9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74c3ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 4)\n",
      "(46,)\n"
     ]
    }
   ],
   "source": [
    "dataset = loadtxt('bankruptTrain.csv', delimiter=',')\n",
    "\n",
    "train_x = dataset[:,0:4]\n",
    "train_y = dataset[:,4]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00361806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.096 -0.007  2.033  0.432]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_x))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87212c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_1 (Normalizati (None, 4)                 9         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 754\n",
      "Trainable params: 745\n",
      "Non-trainable params: 9\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  normalizer,\n",
    "  tf.keras.layers.Dense(24,  activation='relu'),\n",
    "  tf.keras.layers.Dense(24, activation='relu'),\n",
    "  layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda57732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.3696\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5652\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6087\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6304\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6739\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.7174\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.7391\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.8043\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.8043\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8696\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7826\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.8261\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.8261\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8261\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7826\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8696\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8261\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8261\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8478\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8478\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8696\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8696\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8261\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8261\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8478\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8478\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8478\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8478\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8696\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.9130\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8913\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8696\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8913\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8696\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8913\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8913\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8696\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8913\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8913\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8696\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8696\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8478\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.9348\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.9130\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.9130\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8913\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.9130\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8913\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.9130\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.9130\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.9348\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.9130\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9130\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8913\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.9130\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.9348\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.9348\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9348\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9348\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.9130\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.9348\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.9348\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2741 - accuracy: 0.9348\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9348\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9348\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8913\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.9348\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.9348\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.9130\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9348\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9348\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9348\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.9130\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9348\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.9348\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9348\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9348\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9348\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9348\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.9348\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9348\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9348\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9348\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9130\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9348\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.9348\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9130\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9130\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9348\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9348\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9130\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9348\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9348\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9130\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9348\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9348\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9130\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9348\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9348\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2111 - accuracy: 0.9348\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9565\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9348\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9348\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9348\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9348\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9348\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9348\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9130\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9348\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9348\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9348\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9348\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9348\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9348\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9348\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9348\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9348\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9348\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9348\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9348\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9348\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9348\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9348\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9348\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9348\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9348\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9348\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9348\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9348\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9348\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9348\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9348\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9348\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9348\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9348\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9348\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9348\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9348\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9130\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9348\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9348\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9348\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9348\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9348\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9348\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9348\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9348\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9348\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9348\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff22e862850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87aecb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9348\n",
      "Accuracy: 93.48\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(train_x, train_y, verbose=1)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ec50b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "dataset_test = loadtxt('bankruptTest.csv', delimiter=',')\n",
    "\n",
    "test_x = dataset_test[:,0:4]\n",
    "test_y = dataset_test[:,4]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5446b21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1474 - accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14741423726081848, 0.9375]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = model.evaluate(test_x, test_y, verbose=1)\n",
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
